{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7yK6MnxDZnMD4/yQlkzin",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kra268/ChemCoder/blob/main/backprop_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Li6UHCJRV-QP"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2, requires_grad=True)      # requires_grad will remember the gradient of all tensors who's PARENT is x\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu7YQJEgWICc",
        "outputId": "e6b7c0fd-a50f-4d87-f499-21053a13dd41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5213, -0.6427], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor([1.0, 0.1], requires_grad=True)\n",
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfR5GtcFo73u",
        "outputId": "efeadf5e-aac1-420f-d9de-6d088ca9d5f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 0.1000], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x*w + 3       # Usually an activation function"
      ],
      "metadata": {
        "id": "-3j1J9GlWT22"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdeHlN3WWaXo",
        "outputId": "48015d3a-ee53-47be-c203-39dd68575622"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.5213, 2.9357], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_act = 5       # Assume this to be actual/true value of y"
      ],
      "metadata": {
        "id": "hJcAtcu_pKsn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = (y_act - y).mean()     # also known as error/ loss_function or loss_fn\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv10TGojpTtT",
        "outputId": "8e173990-b646-4028-920d-918f02a0f670"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7715, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()     # backpropagates the loss/error"
      ],
      "metadata": {
        "id": "oW_kPf6IWv_l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bzaMiO2W0QM",
        "outputId": "3a69aac1-e4b4-48a7-aff0-702a40b48fd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5000, -0.0500])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "  y = x*w + 3\n",
        "  loss = (y_act - y).mean()# This would usually be the loss function\n",
        "  loss.backward()\n",
        "  print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoKl7GCQW5wx",
        "outputId": "f97424a7-c0a2-496a-b0a9-e4055f0ccef7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.0000, -0.1000])\n",
            "tensor([-1.5000, -0.1500])\n",
            "tensor([-2.0000, -0.2000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bguLhVGnwPA",
        "outputId": "4ed7b620-d7ba-4ede-9f2f-12a73dd0bcc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "  y = x*w + 3\n",
        "  loss = (y_act - y).mean()# This would usually be the loss function\n",
        "  loss.backward()\n",
        "  print(x.grad)\n",
        "  x.grad.zero_()        # Make the gradients '0' before the next iteration"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLZEpb9WnKdF",
        "outputId": "a142a9d0-b8c1-487b-a492-cc2786eab734"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5000, -0.0500])\n",
            "tensor([-0.5000, -0.0500])\n",
            "tensor([-0.5000, -0.0500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Ky5Zh6qtR1",
        "outputId": "80a3ee9a-442e-4b97-aea1-ca6b9e5d7e4d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 0.1000], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the weights using an optimizer.\n",
        "# There are many types but more on that later.\n",
        "optimizer = torch.optim.Adam([w], lr=0.01)"
      ],
      "metadata": {
        "id": "lIXxSfMInq6e"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(3):\n",
        "  y = x*w + 3\n",
        "  loss = (y_act - y).mean()# This would usually be the loss function\n",
        "  loss.backward()\n",
        "  optimizer.step()        # This updates the parameters based on the gradient\n",
        "  print(f'this is gradient of x {x.grad}')\n",
        "  print(f'this is w {w}')\n",
        "  x.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63hI3BPcopU_",
        "outputId": "96b9fdba-b5b8-4359-e27a-fe0bfd635101"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is gradient of x tensor([-0.5000, -0.0500])\n",
            "this is w tensor([1.0100, 0.0900], requires_grad=True)\n",
            "this is gradient of x tensor([-0.5050, -0.0450])\n",
            "this is w tensor([1.0200, 0.0800], requires_grad=True)\n",
            "this is gradient of x tensor([-0.5100, -0.0400])\n",
            "this is w tensor([1.0300, 0.0700], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExWDuRTmM4yD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}